## Background

Students (sid, sname, major, gpa)
Enroll   (sid, cid, semester, grade)

Enroll:
  40 bytes / record
  100 records / page
  1,000 pages total
  100,000 tuples total

Student:
  50 bytes / tuple
  80 tuples / page
  500 pages
  40,000 tuples

    SELECT S.sname
    FROM Student S, Enroll E
    WHERE S.sid = E.sid
    AND  E.cid = 437  (1%)
    AND S.gpa > 3.5   (10%)

Buffer Pool (B) = 5

# Costs

## Full table join

          π sname
            |
        σa gpa > 3.5
            |
        σa cid = 437
            |
        ∞ S.sid = E.sid
        /         \
    Student     Enroll

### Page Nested Loop

  read 500 records from S
  + Loop through 1,000 pages in E * 500 pages in S
  = 500,500

### Block nested loop

Student as Outer:

   500 pages from S + floor(500 pages / B - 2) * 1000 pages in E
   = 500 + floor(500/3) * 1000
   = 167,500

Enroll as Outer:

   1000 pages from E + floor(1000 pages / 3) * 500 pages in S
   = 168,000

### Sort Merge Join

    Sorting S: log4(500) * (2 * 500)
               = 5000
    Sorting E: log4(1000) * (2 * 1000)
               = 10,000
    Merging: 1,500

    Total: 16,500

### Hash Join

    (4 * 2) * 1500 to build the hash table
    + 1500
    = 13,500

## Optimized Joins

We can make our joins faster by pushing the select down the tree.

            π sname
                |
        ∞ S.sid = E.sid
        /           \
    σa gpa > 3.5  σa cid = 437
        |            |
    Student         Enroll



How much do the earlier selects cost?

    10% of Students = 50 pages
    1% of Enroll = 10 pages

    Total Cost = 500 reads from S
               + 1000 reads from E
               + 50 writes for S
               + 10 writes for E
               = 1,650 I/Os

### Page nested loop

    1560 + 50 + (50 * 10)
    = 2,110

    1560 + 10 + (10 * 50)
    = 2,070

### Block Nested Loop

    1560 + 50 + floor(50/3) * 10
    = 1,780

    1560 + 10 + floor(10/3) * 50
    = 1,770

### Sort Merge Join

    Selects: 1560
    Sort S: 3 * 2 * 50 = 300
    Sort E: 2 * 2 * 10 = 40
    SMJ: 60

    Total: 1,960

### Hash Join

    1,560 + 180 = 1,740

## Pipeling

You don't have to wait for one query to be completely done to work on another
query.  In this case, while I'm reading S using a sequential scan, every time
there is an output that matches the selection, I put it in my buffer and do
the compution on E with the buffers in Main Memory.  By doing this, I save on
the output and input of writing the selected data to disk.

The reason we like left leaf trees is that the result of each join can be
pipelined into the next join.

We can save some cost for both Page Nested Loops and Block Nested Loops by
doing this.

## Pushing down the projection

We can optimize the query further by remove the attributes from tuples that we
don't need during the selection.  For student we only need sid and sname (30
bytes) and from Enroll we only need sid (10 bytes).

          π sname
              |
      ∞ S.sid = E.sid
      /           \
  π sname, sid    π sid
      |              |
  σa gpa > 3.5    σa cid = 437
      |              |
    Student         Enroll

How much do the earlier selects cost?

10% of Students * 60% record size = 30 pages
1% of Enroll * 25% record size = 3 pages

Total Cost = 500 reads from S
   + 1000 reads from E
   + 30 writes for S
   + 3 writes for E
   = 1,533 I/Os

### Page nested loop

1533 + 30 + (30 * 3)
= 1,653

1533 + 30 + (30 * 3)
= 1,626

### Block Nested Loop

1533 + 30 + floor(30/3) * 3
= 1,593

1533 + 3 + floor(3/3) * 30
= 1,566

### Sort Merge Join

Selects: 1533
Sort S: 3 * 2 * 30 = 180
Sort E: 2 * 3 = 6
SMJ: 33

Total: 1,752

### Index Nested Loop

The inner relation is the one we have the index on during the join

Unoptimized:

      1,000 pages in E
    + 100,000 * 1.2
    = 121,000

Pushing the selection:

      1,010 I/Os to match E
    + 10 pages in E
    + 1,000 * 1.2
    = 2,220

We can't push the projection on the student table because we would lose the
advantage of the index on sid.

Pushing the projection (on E):

      1,010 I/Os to match E
    + 3 pages in E
    + 1,000 * 1.2
    = 2,206

# System R

What information does System R use to optimize queries?

 - Uses the left deep plan
 - Statistic -> catalog per relation
    - # of tuples
    - # of pages
    - size of tuples
    - # of distinct values
    - min, max
    - index info

